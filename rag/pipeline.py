#Kh·ªëi import
import json
import re
from rag.config import RAGConfig
from rag.router import route_query
from rag.normalize import normalize_query
from rag.text_utils import is_listing_query, extract_img_keys
from rag.retriever import search as retrieve_search
from rag.scoring import fused_score
from rag.context_builder import choose_adaptive_max_ctx, build_context_from_hits
from rag.memory.conversation_manager import read_memory, log_event, build_conversation_text, write_memory
from rag.memory.summarizer import summarize_to_fact
from rag.conversation_state import conversation_state
from rag.query_rewriter import needs_rewrite, format_history, rewrite_query_with_llm
from rag.answer_modes import decide_answer_policy
from rag.generator import call_finetune_with_context_stream
from rag.tag_filter import tag_filter_pipeline
from rag.logging.timing_logger import TimingLog
from rag.reasoning.multi_hop import multi_hop_controller
from typing import List, Tuple, Dict, Any
from rag.logging.debug_log import debug_log
# from rag.post_answer.enricher import enrich_answer_if_needed
from pathlib import Path

FORCE_MUST_TAGS = {
    "mechanisms:luu-dan-manh",
    "mechanisms:luu-dan",
    "mechanisms:tiep-xuc-manh",
    "mechanisms:tiep-xuc",
    "mechanisms:tiep-xuc-luu-dan-manh",
    "mechanisms:tiep-xuc-luu-dan",
    "mechanisms:xong-hoi-manh",
    "mechanisms:xong-hoi",
    "mechanisms:co-chon-loc",
    "mechanisms:khong-chon-loc",
}

FORMULA_TRIGGERS = [
    
    "c√¥ng th·ª©c",
    "ph·ªëi tr·ªôn",
    "ph·ªëi h·ª£p thu·ªëc",
    "li·ªÅu ph·ªëi",
    "ph·ªëi",
    "pha thu·ªëc",
    "c√¥ng th·ª©c tr·ªã",
    "c√¥ng th·ª©c tr·ª´",
    "c√¥ng th·ª©c di·ªát",
    "ph√°c ƒë·ªì",
    "k·∫øt h·ª£p thu·ªëc",
    "ho·∫°t ch·∫•t l∆∞u d·∫´n ph√π h·ª£p",
]

#chu·∫©n h√≥a c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng
def norm(s: str) -> str:
    if not s:
        return ""
    s = s.lower()
    s = s.replace("-", " ").replace("_", " ")
    s = re.sub(r"[^\w\s]", " ", s)
    s = re.sub(r"\s+", " ", s)
    return s.strip()

#Nh·∫≠n di·ªán truy v·∫•n d·∫°ng ph·ªëi c√¥ng th·ª©c
def is_formula_query(query: str, tags: dict) -> bool:

    has_plus = "+" in query
    has_mechanisms = any(
        t.startswith("mechanisms:")
        for t in tags.get("must", []) + tags.get("soft", [])
    )

    # N·∫øu c√≥ nhi·ªÅu h∆°n 1 mechanism tag -> g·∫ßn nh∆∞ ch·∫Øc ch·∫Øn l√† ph·ªëi
    num_mechs = sum(
        1 for t in tags.get("must", []) + tags.get("soft", [])
        if t.startswith("mechanisms:")
    )

    if has_mechanisms and (has_plus or num_mechs >= 2):
        return True

    return False

#T√¨m ki·∫øm theo ch·∫ø ƒë·ªô c√¥ng th·ª©c (kh√¥ng d√πng multi-hop)
def formula_mode_search(
    *,
    client,
    kb,
    norm_query: str,
    must_tags: List[str],
):
    """
    Budget-aware:
    - T·ªïng ng√¢n s√°ch = RAGConfig.max_ctx_soft
    - Chia ƒë·ªÅu cho m·ªói must_tag
    - N·∫øu ch∆∞a ƒë·ªß ‚Üí ch·∫°y free search ƒë·ªÉ b√π
    """

    max_ctx = RAGConfig.max_ctx_soft

    must_tags = list(must_tags or [])
    num_tags = max(len(must_tags), 1)

    # ng√¢n s√°ch cho m·ªói tag
    per_tag_k = max(1, max_ctx // num_tags)

    all_results = []

    # ---- ROLE 1: MUST TAG (chia ng√¢n s√°ch) ----
    for m in must_tags:
        print("m:", m)
        hits = retrieve_search(
            client=client,
            kb=kb,
            norm_query=norm_query,
            top_k=per_tag_k,
            must_tags=[m],
            any_tags=[]
        )
        all_results.extend(hits)

    # dedupe theo id
    unique = {}
    for h in all_results:
        hid = h.get("id")
        if hid:
            prev = unique.get(hid)
            if not prev or h.get("score", 0) > prev.get("score", 0):
                unique[hid] = h

    results = list(unique.values())

    # ---- ROLE 2: FREE SEARCH (b√π slot c√≤n thi·∫øu) ----
    remaining = max_ctx - len(results)

    if remaining > 0:
        hits_free = retrieve_search(
            client=client,
            kb=kb,
            norm_query=norm_query,
            top_k=remaining,
            must_tags=[],
            any_tags=[]
        )

        for h in hits_free:
            hid = h.get("id")
            if hid and hid not in unique:
                unique[hid] = h
                if len(unique) >= max_ctx:
                    break

        results = list(unique.values())

    # hard cap an to√†n
    return results[:max_ctx]

#Chu·∫©n h√≥a tag
def strip_tag_ns(s):
    if not s:
        return ""
    out = []
    for part in s.split("|"):
        if ":" in part:
            out.append(part.split(":",1)[1])
        else:
            out.append(part)
    return " ".join(out)

#Ph√¢n t√°ch doc ƒë·ªÉ ph·ª•c v·ª•  x·ª≠ l√Ω match key word trong q,a,alt
def doc_blob(h):
    return norm(
        (h.get("question","") or "") + " " +
        (h.get("answer","") or "") + " " +
        " ".join(h.get("alt_questions",[]) or []) + " " +
        strip_tag_ns(h.get("tags_v2",""))
    )

#Chu·∫©n h√≥a tag
def strip_ns(t):
    if ":" in t:
        t = t.split(":",1)[1]
    return t

#Filter DOC match tags/keyword
def evidence_gate_by_tags(hits, must_tags, any_tags):
    must_tags = [norm(strip_ns(t)) for t in must_tags]
    any_tags  = [norm(strip_ns(t)) for t in any_tags]

    kept = []

    for h in hits:
        blob = norm(
            (h.get("question","") or "") + " " +
            (h.get("answer","") or "") + " " +
            " ".join(h.get("alt_question",[]) or []) + " " +
            strip_tag_ns(h.get("tags_v2",""))
        )

        must_hit = sum(1 for t in must_tags if t in blob)
        any_hit  = sum(1 for t in any_tags  if t in blob)

        if must_hit >= 1 or any_hit >= 1:
            kept.append((must_hit, any_hit, h))

    kept.sort(key=lambda x: (x[0], x[1]), reverse=True)

    return [h for _,_,h in kept[:RAGConfig.max_ctx_soft]]

#ƒê√°nh d·∫•u th·ª© t·ª± g·ªëc t·ª´ search() ƒë·ªÉ pipeline KH√îNG l√†m x√°o tr·ªôn
def preserve_search_order(hits):
    for idx, h in enumerate(hits):
        h["_search_rank"] = idx
    return hits

#C·ªông ƒëi·ªÉm tag match
def _count_tag_hits(h, any_tags, must_tags):
    tv2 = str(h.get("tags_v2") or "")
    score = 0
    for t in (must_tags or []):
        if t and t in tv2:
            score += 3
    for t in (any_tags or []):
        if t and t in tv2:
            score += 1
    return score

#Promt ph·ª•c v·ª• ƒëi nh√°nh GLOBAL
def _global_system_prompt() -> str:
    return """
B·∫°n l√† chuy√™n gia BVTV/n√¥ng h·ªçc t·∫°i Vi·ªát Nam. M·ª•c ti√™u: cung c·∫•p c√¢u tr·∫£ l·ªùi CH·∫§T L∆Ø·ª¢NG CAO theo phong c√°ch gi√°o tr√¨nh/chuy√™n kh·∫£o,
gi·∫£i th√≠ch r√µ r√†ng, c√≥ chi·ªÅu s√¢u, gi√†u v√≠ d·ª• th·ª±c t·∫ø trong canh t√°c Vi·ªát Nam.

TI√äU CHU·∫®N CH·∫§T L∆Ø·ª¢NG (B·∫ÆT BU·ªòC):
- ∆Øu ti√™n: ch√≠nh x√°c, m·∫°ch l·∫°c, c√≥ t√≠nh ‚Äúgi·∫£i th√≠ch ƒë∆∞·ª£c‚Äù (explainable), kh√¥ng n√≥i chung chung.
- Tr√¨nh b√†y theo c·∫•u tr√∫c r√µ r√†ng, c√≥ ti√™u ƒë·ªÅ; d√πng bullet v√† b·∫£ng (n·∫øu h·ªØu √≠ch).
- Lu√¥n ph√¢n bi·ªát: (i) ƒëi·ªÅu ch·∫Øc ch·∫Øn/ph·ªï qu√°t, (ii) ƒëi·ªÅu ph·ª• thu·ªôc b·ªëi c·∫£nh (c√¢y, giai ƒëo·∫°n, th·ªùi ti·∫øt, √°p l·ª±c d·ªãch h·∫°i), (iii) ƒëi·ªÅu c·∫ßn th√™m d·ªØ li·ªáu.
- Khi thu·∫≠t ng·ªØ/ƒë·ªëi t∆∞·ª£ng c√≥ nhi·ªÅu c√°ch g·ªçi t·∫°i VN: n√™u t√™n th∆∞·ªùng g·ªçi + m√¥ t·∫£ nh·∫≠n di·ªán; tr√°nh b·ªãa t√™n lo√†i.
- N·∫øu thi·∫øu d·ªØ li·ªáu ƒë·ªÉ k·∫øt lu·∫≠n ch·∫Øc: n√≥i r√µ ‚Äúph·ª• thu·ªôc/ c·∫ßn x√°c minh‚Äù v√† ƒë∆∞a ti√™u ch√≠/quan s√°t ƒë·ªÉ ng∆∞·ªùi d√πng t·ª± ki·ªÉm ch·ª©ng.

C·∫§U TR√öC C√ÇU TR·∫¢ L·ªúI CHU·∫®N:
1) T√≥m t·∫Øt nhanh (2‚Äì4 d√≤ng): tr·∫£ l·ªùi tr·ª±c di·ªán c√¢u h·ªèi.
2) ƒê·ªãnh nghƒ©a/kh√°i ni·ªám c·ªët l√µi (ng·∫Øn g·ªçn).
3) ƒê·∫∑c ƒëi·ªÉm nh·∫≠n bi·∫øt / ƒëi·ªÉm then ch·ªët (3‚Äì7 bullet).
4) C∆° ch·∫ø / nguy√™n l√Ω (n·∫øu li√™n quan): gi·∫£i th√≠ch ·ªü m·ª©c v·ª´a ƒë·ªß, tr√°nh thu·∫≠t ng·ªØ qu√° h√†n l√¢m nh∆∞ng ph·∫£i ƒë√∫ng.
5) Ph√¢n lo·∫°i (CH·ªà KHI c√¢u h·ªèi h·ªèi ‚Äúg·ªìm nh·ªØng lo·∫°i n√†o/bao g·ªìm/ph√¢n lo·∫°i‚Äù): k√®m ti√™u ch√≠ ph√¢n bi·ªát.
6) V√≠ d·ª• ƒë·∫°i di·ªán: ∆∞u ti√™n nh√≥m/case ph·ªï bi·∫øn trong canh t√°c Vi·ªát Nam (n√™u 3‚Äì8 v√≠ d·ª• ph√π h·ª£p).
7) Sai l·∫ßm th∆∞·ªùng g·∫∑p & c√°ch tr√°nh (2‚Äì5 √Ω) ‚Äî ch·ªâ n√™u khi gi√∫p √≠ch tr·ª±c ti·∫øp.
8) C√¢u h·ªèi c·∫ßn l√†m r√µ (2‚Äì6 c√¢u): ƒë·ªÉ ch·ªët quy·∫øt ƒë·ªãnh th·ª±c t·∫ø theo b·ªëi c·∫£nh ng∆∞·ªùi d√πng.

QUY T·∫ÆC TR·∫¢ L·ªúI:
- Kh√¥ng lan man sang ch·ªß ƒë·ªÅ ngo√†i tr·ªçng t√¢m c√¢u h·ªèi.
- Kh√¥ng ‚Äút·ªè ra ch·∫Øc ch·∫Øn‚Äù khi thi·∫øu c∆° s·ªü; kh√¥ng suy di·ªÖn v∆∞·ª£t qu√° th√¥ng tin ƒë·∫ßu v√†o.
- D√πng thu·∫≠t ng·ªØ BVTV quen thu·ªôc t·∫°i Vi·ªát Nam; n·∫øu d√πng thu·∫≠t ng·ªØ qu·ªëc t·∫ø th√¨ gi·∫£i th√≠ch ng·∫Øn k√®m theo.
- VƒÉn phong chuy√™n nghi·ªáp, d·ªÖ hi·ªÉu; ∆∞u ti√™n v√≠ d·ª• v√† ti√™u ch√≠ ph√¢n bi·ªát h∆°n l√† l√Ω thuy·∫øt d√†i d√≤ng.
""".strip()

#Core GPT
def answer_with_suggestions_stream(*, user_id, user_query, kb, client, cfg, policy):
    """
    Streaming version: yield t·ª´ng chunk text cho frontend.
    Gi·ªØ nguy√™n pipeline logic ch√≠nh, ch·ªâ ƒë·ªïi b∆∞·ªõc generate sang stream.
    """
    timer = TimingLog(user_query)
    turns = conversation_state.get_turns(user_id)
    effective_query = user_query

    # 1) rewrite (gi·ªØ nh∆∞ b·∫£n th∆∞·ªùng)
    if turns and needs_rewrite(user_query):
        history_text = format_history(turns)
        try:
            rewritten = rewrite_query_with_llm(
                client=client,
                user_query=user_query,
                history_text=history_text,
            )
            if rewritten:
                effective_query = rewritten
        except Exception as e:
            print("[QUERY REWRITE ERROR]:", e)

    # 2) route + normalize
    route = route_query(client, effective_query)
    if route == "GLOBAL":
        model = "gpt-4.1"

        yield "üåç ƒêang tr·∫£ l·ªùi b·∫±ng tri th·ª©c t·ªïng qu√°t...\n\n"

        resp = client.chat.completions.create(
            model=model,
            temperature=0.25,
            messages=[
                {"role": "system", "content": _global_system_prompt()},
                {"role": "user", "content": effective_query},
            ],
            stream=True,
        )

        parts = []
        for chunk in resp:
            try:
                delta = chunk.choices[0].delta
                if delta and getattr(delta, "content", None):
                    parts.append(delta.content)
                    yield delta.content
            except Exception:
                continue

        final_text = "".join(parts)

        # memory + log y nh∆∞ non-stream
        conversation_state.append(user_id, "user", user_query)
        conversation_state.append(user_id, "assistant", final_text)

        log_event(user_id, "user", user_query)
        log_event(user_id, "assistant", final_text)

        timer.finish(RAGConfig.enable_timing_log)

        return
    timer.start("normalize")
    norm_query = normalize_query(client, effective_query)
    norm_lower = norm_query.lower()
    timer.end("normalize")

    # 3) read memory (gi·ªØ nh∆∞ b·∫£n th∆∞·ªùng)
    timer.start("read_memory and check route")
    memory_facts = read_memory(client=client, user_id=user_id, query=norm_query)
    memory_prompt = ""
    if memory_facts:
        memory_prompt = "USER MEMORY:\n" + "\n".join(f"- {m['fact']}" for m in memory_facts)

    force_rag = any(k in norm_lower for k in FORMULA_TRIGGERS)
    if force_rag:
        route = "RAG"
    timer.end("read_memory and check route")

    # (tu·ª≥ ch·ªçn) stream status cho UI
    yield "‚è≥ ƒêang truy v·∫•n d·ªØ li·ªáu...\n\n"

    # 4) tag filter pipeline (gi·ªØ nh∆∞ b·∫£n th∆∞·ªùng)
    timer.start("tag_filter_pipeline running")
    result = tag_filter_pipeline(norm_query)
    must_tags = result.get("must", [])
    any_tags  = result.get("any", [])
    timer.end("tag_filter_pipeline running")

    # 5) retrieval
    is_list = is_listing_query(norm_query)
    if is_formula_query(norm_query, {"must": must_tags, "soft": any_tags}):
        hits = formula_mode_search(client=client, kb=kb, norm_query=norm_query, must_tags=must_tags)
    else:
        hits = multi_hop_controller(
            client=client,
            kb=kb,
            base_query=norm_query,
            must_tags=must_tags,
            any_tags=any_tags,
        )

    print("QUERY      :", norm_query)
    print("MUST TAGS  :", must_tags)
    print("ANY TAGS   :", any_tags)
    debug_log("QUERY      :", norm_query)
    debug_log("MUST TAGS  :", must_tags)
    debug_log("ANY TAGS   :", any_tags)

    timer.start("build_context running")

    if not hits:
        yield "Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu ph√π h·ª£p."
        return
    
    for h in hits:
        h["fused_score"] = fused_score(h)
        h["tag_hits"] = _count_tag_hits(h, any_tags, must_tags)

    hits = preserve_search_order(hits)

    primary_doc = hits[0]

    # 6) build context
    base_ctx = choose_adaptive_max_ctx(hits, is_listing=is_list)
    max_ctx = min(RAGConfig.max_ctx_strict, base_ctx)

    policy = decide_answer_policy(effective_query, primary_doc, force_listing=is_list)

    off_filter_tag_on_doc = policy.intent not in {"disease"}  # y h·ªát logic g·ªëc :contentReference[oaicite:7]{index=7}
    if not off_filter_tag_on_doc:
        hits = evidence_gate_by_tags(hits, must_tags=must_tags, any_tags=any_tags)

    context = build_context_from_hits(hits[:max_ctx])

    yield "‚úçÔ∏è ƒêang t·ªïng h·ª£p c√¢u tr·∫£ l·ªùi...\n\n"

    # 7) generate streaming
    answer_mode_final = ("listing" if policy.format == "listing" else policy.intent)
    timer.start("ttft")
    timer.start("gpt_stream_total") 
    first_tok = True
    parts = []
    for tok in call_finetune_with_context_stream(
        system_prefix=memory_prompt,
        client=client,
        user_query=effective_query,
        context=context,
        answer_mode=answer_mode_final,
        must_tags=must_tags,
        any_tags=any_tags,
    ):
        if first_tok:
            timer.end("ttft")
            first_tok = False
        parts.append(tok)
        yield tok
    timer.end("gpt_stream_total")
    final_answer = "".join(parts)

    try:
        from rag.logging.logger_csv import append_log_to_csv
        from run.main import BASE_DIR

        csv_path = str(BASE_DIR / "rag_logs.csv")

        append_log_to_csv(
            csv_path,
            user_query,
            norm_query,
            context,
            {
                "text": final_answer,
                "route": route,
                "norm_query": norm_query,
            },
            route
        )

    except Exception as e:
        print("[RAG CSV LOG ERROR]:", e)


    # 8) enrich (‚ö†Ô∏è enrich l√† 1 call LLM n·ªØa n√™n s·∫Ω ‚Äúƒë·ª©ng‚Äù; c√≥ 2 l·ª±a ch·ªçn)
    # Option A (khuy·∫øn ngh·ªã cho streaming m∆∞·ª£t): b·ªè enrich trong stream
    # Option B: enrich xong r·ªìi append th√™m ph·∫ßn "B·ªï sung" sau c√πng (kh√¥ng stream)
    # final_answer = enrich_answer_if_needed(...)

    # 9) write memory/log (gi·ªØ nh∆∞ b·∫£n th∆∞·ªùng)
    conversation_state.append(user_id, "user", user_query)
    conversation_state.append(user_id, "assistant", final_answer)
    log_event(user_id, "user", user_query)
    log_event(user_id, "assistant", final_answer)

    try:
        conv_text = build_conversation_text(user_id)
        facts_raw = summarize_to_fact(client, conv_text)
        facts = json.loads(facts_raw)
        write_memory(client, user_id, facts)
    except Exception as e:
        print("[MEMORY WRITE ERROR]:", e)

    timer.finish(RAGConfig.enable_timing_log)
